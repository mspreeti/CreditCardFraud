{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6dbf77",
   "metadata": {},
   "source": [
    "CLASSFIFICATION MODELS: (Binary features)\n",
    "\n",
    "Binary Classification: Classification task with two possible outcomes. Eg: Gender classification (Male / Female)\n",
    "\n",
    "Multi-class classification: Classification with more than two classes. In multi class classification each sample is assigned to one and only one target label. Eg: An animal can be cat or dog but not both at the same time\n",
    "\n",
    "Multi-label classification: Classification task where each sample is mapped to a set of target labels (more than one class). Eg: A news article can be about sports, a person, and location at the same time.\n",
    "\n",
    "1. Logistic Regression: \n",
    "Advantages: Logistic regression is designed for this purpose (classification), and is most useful for understanding the influence of several independent variables on a single outcome variable.\n",
    "\n",
    "Disadvantages: Works only when the predicted variable is binary, assumes all predictors are independent of each other and assumes data is free of missing values.\n",
    "\n",
    "2. Support Vector Machine\n",
    "Definition: Support vector machine is a representation of the training data as points in space separated into categories by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.\n",
    "\n",
    "Advantages: Effective in high dimensional spaces and uses a subset of training points in the decision function so it is also memory efficient.\n",
    "\n",
    "Disadvantages: The algorithm does not directly provide probability estimates, these are calculated using an expensive five-fold cross-validation.\n",
    "\n",
    "3. Ensemble technique: Random Forest CLassifier\n",
    "Definition: Random forest classifier is a meta-estimator that fits a number of decision trees on various sub-samples of datasets and uses average to improve the predictive accuracy of the model and controls over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement.\n",
    "\n",
    "Advantages: Reduction in over-fitting and random forest classifier is more accurate than decision trees in most cases.Can handle large datasets. Will output the importance of variables. Can handle missing values.\n",
    "\n",
    "Disadvantages: Slow real time prediction, difficult to implement, and complex algorithm.\n",
    "\n",
    "4. KNN\n",
    "Definition: Neighbours based classification is a type of lazy learning as it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the k nearest neighbours of each point.\n",
    "\n",
    "Advantages: This algorithm is simple to implement, robust to noisy training data, and effective if training data is large.Easy to use, understand and interpret.\n",
    "Quick calculation time.\n",
    "No assumptions about data.\n",
    "High accuracy of predictions.\n",
    "Versatile – Can be used for both Classification and Regression Business Problems.\n",
    "Can be used for Multi Class Problems as well.\n",
    "We have only one Hyper parameter to tweak at Hyperparameter Tuning step.\n",
    "\n",
    "Disadvantages: Need to determine the value of K and the computation cost is high as it needs to compute the distance of each instance to all the training samples.\n",
    "\n",
    "5. Decision Tree\n",
    "Definition: Given a data of attributes together with its classes, a decision tree produces a sequence of rules that can be used to classify the data.\n",
    "\n",
    "Advantages: Decision Tree is simple to understand and visualise, requires little data preparation, and can handle both numerical and categorical data. \n",
    "\n",
    "Disadvantages: Decision tree can create complex trees that do not generalise well, and decision trees can be unstable because small variations in the data might result in a completely different tree being generated.\n",
    "\n",
    "6. Stochastic Gradient Descent\n",
    "Definition: Stochastic gradient descent is a simple and very efficient approach to fit linear models. It is particularly useful when the number of samples is very large. It supports different loss functions and penalties for classification.\n",
    "Advantages: Efficiency and ease of implementation.\n",
    "Disadvantages: Requires a number of hyper-parameters and it is sensitive to feature scaling.\n",
    "from sklearn.linear_model import SGDClassifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ce35f",
   "metadata": {},
   "source": [
    "Comparison Matrix\n",
    "Accuracy: (True Positive + True Negative) / Total Population\n",
    "Accuracy is a ratio of correctly predicted observation to the total observations. Accuracy is the most intuitive performance measure.\n",
    "True Positive: The number of correct predictions that the occurrence is positive\n",
    "True Negative: The number of correct predictions that the occurrence is negative\n",
    "F1-Score: (2 x Precision x Recall) / (Precision + Recall)\n",
    "F1-Score is the weighted average of Precision and Recall used in all types of classification algorithms. Therefore, this score takes both false positives and false negatives into account. F1-Score is usually more useful than accuracy, especially if you have an uneven class distribution.\n",
    "Precision: When a positive value is predicted, how often is the prediction correct?\n",
    "Recall: When the actual value is positive, how often is the prediction correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cb387b",
   "metadata": {},
   "source": [
    "##Problem Statement:##\n",
    "\n",
    "The datasets contains transactions made by credit cards in September 2013 by european cardholders. This dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n",
    "\n",
    "It contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n",
    "\n",
    "Given the class imbalance ratio, we recommend measuring the accuracy using the Area Under the Precision-Recall Curve (AUPRC). Confusion matrix accuracy is not meaningful for unbalanced classification.\n",
    "\n",
    "Please cite: Andrea Dal Pozzolo, Olivier Caelen, Reid A. Johnson and Gianluca Bontempi. Calibrating Probability with Undersampling for Unbalanced Classification. In Symposium on Computational Intelligence and Data Mining (CIDM), IEEE, 2015\n",
    "\n",
    "https://data.world/preetims/fraud-detection/workspace/project-summary?agentid=raghu543&datasetid=credit-card-fraud-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decece42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\prash\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.1 in c:\\users\\prash\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\prash\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\prash\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\prash\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.19.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\prash\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "!pip install -U imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a799371d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"creditcard.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc663ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "780cb26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This shows the highly imbalanced set. \n",
    "dataset['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cca5f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/framework-for-imbalanced-classification-projects/\n",
    "#Selecting metric: Here, Class:1 is a fraud transaction, <80% of total class, hence ACCURACY should not be used, \n",
    "#confusion matrix shall be baised. Best metric: F1 measure, AUPRC\n",
    "\n",
    "#Start cross-validation and apply algorithms, Check for correlation of features with Class and thus apply hyperparameter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f49aab11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#CORRELATION\n",
    "corr = dataset.corr()\n",
    "f,ax = plt.subplots(figsize=(15,10) )\n",
    "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", fmt='.1f',cbar=True,ax=ax, square=True, xticklabels= True, yticklabels= True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9ed869",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop('Class', axis=1)\n",
    "y = dataset['Class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9caa5b1",
   "metadata": {},
   "source": [
    "Technique 0: Collect more data, if possible. \n",
    "Technique 1: Pick decision tree based approaches as they work better than logistic regression or SVM. Random Forest is a good algorithm to try but beware of over fitting. \n",
    "Technique 2: Up-sample minority class\n",
    "Technique 3: Down-sample majority class \n",
    "Technique 4: A combination of Over and under sampling. \n",
    "Technique 5: Penalize learning algorithms that increase cost of classification mistakes on minority classes.\n",
    "Technique 6: Generate synthetic data (SMOTE, ADASYN)\n",
    "Technique 7: Add appropriate weights to your deep learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7232465f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure: 0.126\n",
      "AUPRC: 0.060\n"
     ]
    }
   ],
   "source": [
    "#Trying the model with class_weights parameter of LogisticReg:\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "lrmodel = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "lrmodel.fit(X_train, y_train)\n",
    "yhat = lrmodel.predict(X_test)\n",
    "# evaluate predictions\n",
    "print('F-Measure: %.3f' % f1_score(y_test, yhat))\n",
    "\n",
    "import sklearn.metrics\n",
    "auprc = sklearn.metrics.average_precision_score(y_test, yhat)\n",
    "print('AUPRC: %.3f' % auprc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4602f2",
   "metadata": {},
   "source": [
    "METRICS FOR IMBALANCED DATASET:\n",
    "\n",
    "F-MEASURE: is a combined score of recall and precision. F1 score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "HOW TO READ F-MEASURE?\n",
    "\n",
    "Unbalanced class, but both classes are important: If the class distribution is highly skewed (such as 80:20 or 90:10), then a classifier can get a low mis-classification rate simply by choosing the majority class. In such a situation, I would choose the classifier that gets high F1 scores on both classes, as well as low mis-classification rate. A classifier that gets low F1-scores should be overlooked.\n",
    "Unbalanced class, but one class if more important that the other. For e.g. in Fraud detection, it is more important to correctly label an instance as fraudulent, as opposed to labeling the non-fraudulent one. In this case, I would pick the classifier that has a good F1 score only on the important class. Recall that the F1-score is available per class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea15dc",
   "metadata": {},
   "source": [
    "AREA UNDER PRECISION-RECALL CURVE(AUPRC):\n",
    "\n",
    "The AUPRC is calculated as the area under the PR curve. A PR curve shows the trade-off between precision and recall across different decision thresholds.\n",
    "\n",
    "Because PR curves don’t use true negatives anywhere, the AUPRC won’t be “swamped” by a large proportion of true negatives in the data. You can use AUPRC on a dataset with 98% negative/2% positive examples, and it will “focus” on how the model handles the 2% positive examples. If the model handles the positive examples well, AUPRC will be high. If the model does poorly on the positive examples, AUPRC will be low. \n",
    "\n",
    "REFERENCE: https://neptune.ai/blog/f1-score-accuracy-roc-auc-pr-auc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470ad78",
   "metadata": {},
   "source": [
    "# OPTION 1: CROSSVALIDATION AND HYPERPARAMETER TUNING\n",
    "for imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52382038",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "log_class=LogisticRegression()\n",
    "grid={'C':10.0**np.arange(-2,3),'penalty':['l1','l2']}\n",
    "cv = KFold(n_splits=5,random_state=None,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b99601b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\prash\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\prash\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\prash\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\prash\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.83797055        nan 0.84604556        nan 0.85042685\n",
      "        nan 0.85315036        nan 0.85345525]\n",
      "  warnings.warn(\n",
      "C:\\Users\\prash\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=GridSearchCV(log_class, grid, cv=cv, n_jobs=-1, scoring='f1_macro')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2094d374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56846    29]\n",
      " [   31    56]]\n",
      "0.9989466661985184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56875\n",
      "           1       0.66      0.64      0.65        87\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.83      0.82      0.83     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba7e3035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure: 0.843\n",
      "AUPRC: 0.717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F-Measure: %.3f' % f1_score(y_test, y_pred))\n",
    "import sklearn.metrics\n",
    "auprc = sklearn.metrics.average_precision_score(y_test, y_pred)\n",
    "print('AUPRC: %.3f' % auprc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e45b5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30525f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56870     5]\n",
      " [   20    67]]\n",
      "0.9995611109160493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56875\n",
      "           1       0.93      0.77      0.84        87\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.89      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = classifier.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c15256",
   "metadata": {},
   "source": [
    "We are looking to improve Precision and Recall rates. Precision:1.00 is best case scenario where we can classify all fraudulent transctions 100%. Recall is sensitivity rate should also be 1.0, where they are no False Negatives reported. \n",
    "Trade-off between Precision and Recall is a tough task. When the policy is stringent, precision shall increase however we cannot say the same for Recall score as Recall shall decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ae079f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure: 0.843\n",
      "AUPRC: 0.717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F-Measure: %.3f' % f1_score(y_test, y_pred2))\n",
    "import sklearn.metrics\n",
    "auprc2 = sklearn.metrics.average_precision_score(y_test, y_pred2)\n",
    "print('AUPRC: %.3f' % auprc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc3cd45",
   "metadata": {},
   "source": [
    "# OPTION 2: OVER-SAMPLING AND UNDERSAMPLING:\n",
    "Nearmiss: undersampling (Not advised as we can lose a major chunk of data)\n",
    "\n",
    "\n",
    "RandomOverSampler: oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "916ce396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:586: FutureWarning: Pass sampling_strategy=0.8 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 227440, 1: 405})\n",
      "The number of classes after fit Counter({0: 506, 1: 405})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from imblearn.under_sampling import NearMiss\n",
    "ns = NearMiss(0.8)\n",
    "X_train_ns,y_train_ns = ns.fit_resample(X_train, y_train)\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bb8b5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_ns = RandomForestClassifier()\n",
    "classifier_ns.fit(X_train_ns, y_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5ed24bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50016  6859]\n",
      " [    7    80]]\n",
      "0.8794635019837787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94     56875\n",
      "           1       0.01      0.92      0.02        87\n",
      "\n",
      "    accuracy                           0.88     56962\n",
      "   macro avg       0.51      0.90      0.48     56962\n",
      "weighted avg       1.00      0.88      0.93     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_ns = classifier_ns.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred_ns))\n",
    "print(accuracy_score(y_test,y_pred_ns))\n",
    "print(classification_report(y_test,y_pred_ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7377cbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure: 0.023\n",
      "AUPRC: 0.011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F-Measure: %.3f' % f1_score(y_test, y_pred_ns))\n",
    "import sklearn.metrics\n",
    "auprc3 = sklearn.metrics.average_precision_score(y_test, y_pred_ns)\n",
    "print('AUPRC: %.3f' % auprc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bad4ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:586: FutureWarning: Pass sampling_strategy=0.75 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 227440, 1: 405})\n",
      "The number of classes after fit Counter({0: 227440, 1: 170580})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "os = RandomOverSampler(0.75)\n",
    "X_train_os, y_train_os = os.fit_resample(X_train, y_train)\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_os)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd114b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_os = RandomForestClassifier()\n",
    "classifier_os.fit(X_train_os, y_train_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf0e6915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56870     5]\n",
      " [   20    67]]\n",
      "0.9995611109160493\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56875\n",
      "           1       0.93      0.77      0.84        87\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.97      0.89      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_os = classifier_os.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred_os))\n",
    "print(accuracy_score(y_test,y_pred_os))\n",
    "print(classification_report(y_test,y_pred_os))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa3bd560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure: 0.843\n",
      "AUPRC: 0.717\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F-Measure: %.3f' % f1_score(y_test, y_pred_os))\n",
    "\n",
    "import sklearn.metrics\n",
    "auprc4 = sklearn.metrics.average_precision_score(y_test, y_pred_os)\n",
    "print('AUPRC: %.3f' % auprc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbb018",
   "metadata": {},
   "source": [
    "# OPTION 3 : SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d1bb803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Counter({0: 227440, 1: 405})\n",
      "After Counter({0: 227440, 1: 227440})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "counter = Counter(y_train)\n",
    "print('Before',counter)\n",
    "smt = SMOTE()\n",
    "X_train_smt, y_train_smt = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "counter = Counter(y_train_smt)\n",
    "print ('After', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95664ab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_smt = RandomForestClassifier()\n",
    "classifier_smt.fit(X_train_smt, y_train_smt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a07b371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[56865    10]\n",
      " [   18    69]]\n",
      "0.9995084442259752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56875\n",
      "           1       0.87      0.79      0.83        87\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.94      0.90      0.92     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_smt = classifier_smt.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_pred_smt))\n",
    "print(accuracy_score(y_test,y_pred_smt))\n",
    "print(classification_report(y_test,y_pred_smt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35a832ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Measure: 0.831\n",
      "AUPRC: 0.693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print('F-Measure: %.3f' % f1_score(y_test, y_pred_smt))\n",
    "import sklearn.metrics\n",
    "auprc5 = sklearn.metrics.average_precision_score(y_test, y_pred_smt)\n",
    "print('AUPRC: %.3f' % auprc5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f5c7f",
   "metadata": {},
   "source": [
    "RandomForestClassifier with SMOTE\n",
    "F-Measure: 0.831\n",
    "AUPRC: 0.693\n",
    "\n",
    "RANDOMFOREST CLASSIFIER WITH OVERSAMPLING\n",
    "F-Measure: 0.843     HIGH\n",
    "AUPRC: 0.717         HIGH\n",
    "\n",
    "RANDOMFOREST CLASSIFIER WITH UNDERSAMPLING\n",
    "F-Measure: 0.023\n",
    "AUPRC: 0.011\n",
    "\n",
    "LOGISTIC REGRESSION WITH CLASS WEIGHTS:\n",
    "F-Measure: 0.126\n",
    "AUPRC: 0.060\n",
    "\n",
    "LOGISTIC REGRESSION WITH HYPER PARAMETER TUNING: GRIDSEARCHCV\n",
    "F-Measure: 0.843         HIGH\n",
    "AUPRC: 0.717             HIGH"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
